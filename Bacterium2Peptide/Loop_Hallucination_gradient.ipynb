{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Un8Vus9RfeSa",
        "outputId": "4c1d7c4a-d1f4-4593-c1de-6ae6bc3ba169"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'AMPLify-Feedback' already exists and is not an empty directory.\n",
            "Requirement already satisfied: Levenshtein in /usr/local/lib/python3.10/dist-packages (0.23.0)\n",
            "Requirement already satisfied: rapidfuzz<4.0.0,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from Levenshtein) (3.5.2)\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/AvonYangXX1/AMPLify-Feedback.git\n",
        "!pip install Levenshtein\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import statistics\n",
        "from Levenshtein import distance as lev\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "import warnings\n",
        "with warnings.catch_warnings():\n",
        "    warnings.simplefilter(action='ignore', category=FutureWarning)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generator = tf.keras.models.load_model('AMPLify-Feedback/model_weights/PeptideGenerator_new.keras')"
      ],
      "metadata": {
        "id": "0dUXRksXfmC_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator.summary()"
      ],
      "metadata": {
        "id": "J7tSERKUhWJI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_oracle():\n",
        "    inputs0 = tf.keras.layers.Input((190,43),name=\"SeqInput\")\n",
        "    inputs1 = tf.keras.layers.Input((326,),name=\"StateInput\")\n",
        "    x = tf.keras.layers.Conv1D(128, 5, activation='relu', name=\"Conv1D_0\")(inputs0) # kernel_size=5 works well\n",
        "    x = tf.keras.layers.Conv1D(128, 5, activation='relu', name=\"Conv1D_1\")(x) # Just two layers work better\n",
        "    x = tf.keras.layers.Flatten(name=\"Flatten_0\")(x)\n",
        "    x = tf.keras.layers.Dense(512, activation=\"relu\", name=\"LearnSeqDense_0\")(x)\n",
        "    x = tf.keras.layers.Concatenate(axis=1, name=\"Concat\")([x, inputs1])\n",
        "    x = tf.keras.layers.Dense(1024, activation=\"relu\", name=\"LearnConcatDense_0\")(x)\n",
        "    x = tf.keras.layers.LayerNormalization(name=\"LayerNorm_0\")(x)\n",
        "    x = tf.keras.layers.Dense(512, activation=\"relu\", name=\"LearnConcatDense_1\")(x)\n",
        "    x = tf.keras.layers.LayerNormalization(name=\"LayerNorm_1\")(x)\n",
        "    x = tf.keras.layers.Dense(1, activation=\"linear\", name=\"Output\")(x)\n",
        "    model = tf.keras.models.Model([inputs0, inputs1], x, name=\"MICPredictor\")\n",
        "    return model"
      ],
      "metadata": {
        "id": "KK6BbgTkf3Nb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "oracle = create_oracle()\n",
        "path = \"AMPLify-Feedback/model_weights/MICPredictor\"\n",
        "for i, layer in enumerate(oracle.layers):\n",
        "    weights = np.load(f\"{path}/layer_{i}_weights.npy\", allow_pickle=True)\n",
        "    layer.set_weights(weights)"
      ],
      "metadata": {
        "id": "D977mDVFggf1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "oracle.summary()"
      ],
      "metadata": {
        "id": "EyQM0g3330Vb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aa_vocal = np.load(\"AMPLify-Feedback/model_weights/SeqTV_vocal.npy\")\n",
        "pep_decoder = tf.keras.layers.StringLookup(vocabulary=aa_vocal[1:], invert=True, oov_token='')\n",
        "species_vocal = np.load(\"AMPLify-Feedback/model_weights/SpeciesTV_vocal.npy\")\n",
        "species_decoder = tf.keras.layers.StringLookup(vocabulary=species_vocal[1:], invert=True, oov_token='')"
      ],
      "metadata": {
        "id": "TE8N74OskM7p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_sequences(generator, latent_dim, num_sequences):\n",
        "    noise = (np.random.rand(num_sequences, latent_dim)-0.5)*2\n",
        "    generated_sequences = generator.predict(noise, verbose=0)\n",
        "    return onehot2seq(generated_sequences)"
      ],
      "metadata": {
        "id": "2WsDGF87ZWil"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def onehot2seq(onehot):\n",
        "  decoded_sequences = []\n",
        "  for s in onehot:\n",
        "    chars_array = pep_decoder(tf.math.argmax([s], axis=2)).numpy().astype('str')\n",
        "    decoded_sequences += [\"\".join(chars) for chars in chars_array]\n",
        "  return decoded_sequences"
      ],
      "metadata": {
        "id": "h9QYIzXEp4MF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def coordinates_grid(num_bins) :\n",
        "  labels = np.round(np.linspace(-1, 1, num_bins), 2)\n",
        "  noise = []\n",
        "  for x in labels:\n",
        "    for y in labels:\n",
        "        noise.append([x, y])\n",
        "  noise = np.array(noise)\n",
        "  num_sequences = len(noise)\n",
        "  return noise, num_sequences, labels"
      ],
      "metadata": {
        "id": "ECs8ksUVnuUz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def hallucination_mapping(num_bins, target):\n",
        "  #Search coordinates in the noise plane\n",
        "  noise, num_sequences, labels = coordinates_grid(num_bins)\n",
        "  # Look up the index of the target bacteria\n",
        "  bacteria = np.zeros(shape=(num_sequences, 326))\n",
        "  index = np.where(species_vocal==target)[0][0]\n",
        "  bacteria[:, index] = 1\n",
        "  return noise, num_sequences, bacteria, labels"
      ],
      "metadata": {
        "id": "lXOwW1NxniwL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualization(noise, MIC, generated_sequences, num_bins, labels, num_sequences, iter, target):\n",
        "    vis_data = np.concatenate([noise, np.array(generated_sequences).reshape(num_sequences, 1), MIC], axis=1)\n",
        "    vis_data = pd.DataFrame(vis_data, columns=[\"Noise_1\", \"Noise_2\", \"Peptide\", \"MIC\"])\n",
        "    vis_data['MIC'] = vis_data['MIC'].astype('float64')\n",
        "    vis_data['Noise_1'] = vis_data['Noise_1'].astype('float64')\n",
        "    vis_data['Noise_2'] = vis_data['Noise_2'].astype('float64')\n",
        "    vis_data['Noise_1_bins'] = pd.cut(vis_data['Noise_1'], bins=num_bins, labels=labels)\n",
        "    vis_data['Noise_2_bins'] = pd.cut(vis_data['Noise_2'], bins=num_bins, labels=labels)\n",
        "\n",
        "    #Print the sequence of the top 3 peptides and their coordinates\n",
        "    top_sequence = vis_data.sort_values(by=['MIC'], ascending=True).head(1)\n",
        "    top_sequence.reset_index(drop=True)\n",
        "    print(top_sequence[['Peptide', 'MIC', 'Noise_1', 'Noise_2']])\n",
        "\n",
        "    # Group the data by the bins and calculate the mean MIC\n",
        "    grouped = vis_data.groupby(['Noise_1_bins', 'Noise_2_bins'])\n",
        "    grid_mic_mean = grouped['MIC'].mean().reset_index()\n",
        "\n",
        "    # Pivot the results to create a grid that `sns.heatmap` can visualize\n",
        "    grid_mic_mean_pivot = grid_mic_mean.pivot(index='Noise_1_bins', columns='Noise_2_bins', values='MIC')\n",
        "    plt.figure()\n",
        "    h = sns.heatmap(grid_mic_mean_pivot.transpose().iloc[::-1],\n",
        "                cmap=sns.cubehelix_palette(as_cmap=True),\n",
        "                cbar_kws={'label': 'Log2 MIC'})\n",
        "    h.set(xlabel=\"Noise Dim 1\", ylabel=\"Noise Dim 2\", title=f\"MIC Landscape for {target.split('_')[0]} {target.split('_')[1]} at iteration {iter}\")\n",
        "    #plt.scatter(top_sequence.Noise_1.item(), top_sequence.Noise_2.item(), s=100, c='red', marker='o')\n",
        "    plt.savefig(f\"{target}_{iter}.png\", dpi=200, bbox_inches='tight')\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "13Tm7aF436zT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def compute_gradient(noise, oracle, bacteria, generator_optimizer):\n",
        "    noise = tf.convert_to_tensor(noise, np.float64)\n",
        "    with tf.GradientTape() as gen_tape:\n",
        "        gen_tape.watch(noise)\n",
        "        generated_onehot = generator(noise, training=True)\n",
        "        generator_loss = tf.reduce_mean(oracle([generated_onehot, bacteria]))\n",
        "    gradients_of_generator = gen_tape.gradient(generator_loss, generator.trainable_variables)\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    return generated_onehot"
      ],
      "metadata": {
        "id": "QdwWf9d0RMlJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def RL_loop(generator, oracle, aa_vocal, pep_decoder, n_bins, target):\n",
        "  average_mic_train, min_mic_train, max_mic_train, median_mic_train, levenstein  = [], [], [], [], []\n",
        "  generator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "  for i in range (n_iter_max) :\n",
        "    #Sequences prediction and gradient computation\n",
        "    noise, num_sequences, bacteria, labels = hallucination_mapping(n_bins, target)\n",
        "    generated_onehot = compute_gradient(noise, oracle, bacteria, generator_optimizer)\n",
        "    generated_sequences = onehot2seq(generated_onehot)\n",
        "\n",
        "    #Oracle results and statistics\n",
        "    MIC = oracle([generated_onehot, bacteria])\n",
        "    average_mic_train += [np.mean(MIC)]\n",
        "    min_mic_train += [np.min(MIC)]\n",
        "    max_mic_train += [np.max(MIC)]\n",
        "    median_mic_train += [np.median(MIC)]\n",
        "    levenstein += [variability_metrics(generated_sequences, aa_vocal, pep_decoder)]\n",
        "\n",
        "    #Visualization of the hallucination map and the top sequences\n",
        "    print(f\"Iter {i+1}/{n_iter_max}; Average MIC {np.mean(MIC):.4f}; Levenshtein {variability_metrics(generated_sequences, aa_vocal, pep_decoder):.4f}\")\n",
        "    visualization(noise, MIC, generated_sequences, n_bins, labels, num_sequences, i, target)\n",
        "\n",
        "  return average_mic_train, min_mic_train, max_mic_train, median_mic_train, levenstein"
      ],
      "metadata": {
        "id": "wbEqlQ5xz8R4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def variability_metrics(sequences, aa_vocal, pep_decoder):\n",
        "  total_lev = 0\n",
        "  index = 0\n",
        "  for s1 in range(len(sequences)):\n",
        "                for s2 in range(s1+1,len(sequences)):\n",
        "                        total_lev += lev(sequences[s1],sequences[s2])\n",
        "                        index += 1\n",
        "  return total_lev/index"
      ],
      "metadata": {
        "id": "j1rS35AR-Y_2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display(parameters):\n",
        "  for p in list(parameters.keys()):\n",
        "    plt.plot(range(len(parameters[p])), parameters[p], linestyle='-', label = p)\n",
        "  plt.legend(loc = \"upper right\")\n",
        "  plt.ylabel(\"Value\")\n",
        "  plt.xlabel(\"Iteration index\")\n",
        "  plt.title(\"Performances with the feedback loop\")\n",
        "  plt.savefig(f\"{list(parameters.keys())[0]}.png\", dpi=200, bbox_inches='tight')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "T9tJGh8JjX7i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_dim = 2\n",
        "n_iter_max = 70\n",
        "n_bins = 101\n",
        "target = 'Bacillus_subtilis'\n",
        "\n",
        "average_mic_train, min_mic_train, max_mic_train, median_mic_train, levenstein = RL_loop(generator, oracle, aa_vocal, pep_decoder, n_bins, target)\n",
        "display({\"Average MIC\" : average_mic_train, \"Minimum MIC\" : min_mic_train, \"Maximum MIC\" : max_mic_train, \"Median MIC\" : median_mic_train})\n",
        "display({\"Average Levenstein distance within the prediction\" : levenstein})\n",
        "generate_sequences(generator, latent_dim, 10)"
      ],
      "metadata": {
        "id": "P_CXFJVM3I6R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator.save(\"PeptideGenerator_new.keras\")\n",
        "#generator.save(\"/content/AMPLify-Feedback-main/model_weights/PeptideGenerator_new.keras\")"
      ],
      "metadata": {
        "id": "TOl6xoNHGCW0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
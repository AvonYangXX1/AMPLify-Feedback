{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**GAN**"
      ],
      "metadata": {
        "id": "PZNppTZBwYnJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1F33NulCRrq",
        "outputId": "daeb2456-29b8-49b7-c9c3-3100664c72c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/AvonYangXX1/AMPLify-Feedback.git\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os"
      ],
      "metadata": {
        "id": "BT9cm0MDt_N8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70224d55-43bf-4174-d582-93932a4f1ba4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'AMPLify-Feedback' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generator\n",
        "def create_autoencoder(seq_length, depth, latent_dim):\n",
        "    inputs0 = tf.keras.layers.Input(shape=(seq_length,depth), name=\"Input0\")\n",
        "    # x = tf.keras.layers.LSTM(512, return_sequences=True, name=\"Encoder_0\")(inputs0)\n",
        "    # x = tf.keras.layers.LSTM(256, return_sequences=True, name=\"Encoder_1\")(x)\n",
        "    # x = tf.keras.layers.LSTM(128, return_sequences=True, name=\"Encoder_2\")(x)\n",
        "    x = tf.keras.layers.Conv1D(32, 5, name=\"Encoder_0\")(inputs0)\n",
        "    x = tf.keras.layers.Conv1D(32, 5, name=\"Encoder_1\")(x)\n",
        "    x = tf.keras.layers.Conv1D(32, 5, name=\"Encoder_2\")(x)\n",
        "    x = tf.keras.layers.GRU(latent_dim, return_sequences=False, name=\"Encoder_3\")(x)\n",
        "    x = tf.keras.layers.RepeatVector(seq_length, name=\"RepeatVector\")(x)\n",
        "    x = tf.keras.layers.GRU(128, return_sequences=True, name=\"Decoder_0\")(x)\n",
        "    x = tf.keras.layers.GRU(128, return_sequences=True, name=\"Decoder_1\")(x)\n",
        "    x = tf.keras.layers.GRU(128, return_sequences=True, name=\"Decoder_2\")(x)\n",
        "    x = tf.keras.layers.Dense(depth, activation=\"softmax\", name=\"Output\")(x)\n",
        "    model = tf.keras.models.Model(inputs=inputs0, outputs=x)\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(1e-3),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "Ghzvubkvwaco"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aa_vocal = np.load(\"AMPLify-Feedback/model_weights/SeqTV_vocal.npy\")\n",
        "pep_decoder = tf.keras.layers.StringLookup(vocabulary=aa_vocal[1:], invert=True, oov_token='')"
      ],
      "metadata": {
        "id": "bZwIUT4nThDJ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def onehot2seq(onehot):\n",
        "    seq = tf.math.argmax(onehot, axis=2)\n",
        "    seq = pep_decoder(seq).numpy().astype('str')\n",
        "    seq = [\"\".join(chars) for chars in seq]\n",
        "    return seq"
      ],
      "metadata": {
        "id": "SECVtYs6CyO5"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_dim = 2\n",
        "seq_length = 190\n",
        "depth = 43\n",
        "np.random.seed(8701)\n",
        "demo_noise = (np.random.rand(1, latent_dim)-0.5)*2\n",
        "autoencoder = create_autoencoder(seq_length, depth, latent_dim)\n",
        "path = \"AMPLify-Feedback/processed_data/gan_train_data\"\n",
        "files = os.listdir(path)\n",
        "epochs = 10\n",
        "for epoch in range(epochs):\n",
        "    print(f\"Epoch {epoch+1}/{epochs}\")\n",
        "    for file in files:\n",
        "        seq = np.load(f\"{path}/{file}\", allow_pickle=True)\n",
        "        seq = tf.one_hot(seq.squeeze(), depth=43)\n",
        "        autoencoder.fit(seq, seq, epochs=1, batch_size=22, verbose=1, validation_split=0.2)\n",
        "        del seq\n",
        "        autoencoder.save(\"drive/MyDrive/MIT687/PeptideAutoencoder.keras\")\n",
        "        decoder = tf.keras.models.Model(inputs=autoencoder.layers[5].input, outputs=autoencoder.layers[-1].output)\n",
        "        demo_seq = decoder(demo_noise)\n",
        "        del decoder\n",
        "        demo_seq = onehot2seq(demo_seq)\n",
        "        print(demo_seq[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_zkRcrnAbit",
        "outputId": "3c74a83d-6eb1-4bee-fd00-75da9169c439"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "810/810 [==============================] - 44s 43ms/step - loss: 2.0093 - accuracy: 0.4039 - val_loss: 1.8677 - val_accuracy: 0.4170\n",
            "MMLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLKKK\n",
            "810/810 [==============================] - 33s 41ms/step - loss: 1.8778 - accuracy: 0.4153 - val_loss: 1.8823 - val_accuracy: 0.4133\n",
            "MMLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKKKKKKK\n",
            "810/810 [==============================] - 31s 38ms/step - loss: 1.8729 - accuracy: 0.4152 - val_loss: 1.9425 - val_accuracy: 0.4194\n",
            "MAKLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKKK\n",
            "810/810 [==============================] - 30s 37ms/step - loss: 1.8712 - accuracy: 0.4149 - val_loss: 1.8577 - val_accuracy: 0.4182\n",
            "MAKKLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLKKKKKKKKK\n",
            "810/810 [==============================] - 32s 39ms/step - loss: 1.8596 - accuracy: 0.4180 - val_loss: 1.8605 - val_accuracy: 0.4178\n",
            "MAKKKKLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLKKKKKKKKKKKKKKKKK\n",
            "810/810 [==============================] - 32s 39ms/step - loss: 1.8574 - accuracy: 0.4187 - val_loss: 1.8613 - val_accuracy: 0.4145\n",
            "MAKKKLLLLLLLLLLLAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKKKKKKKKKKKKKKKKKKKKKKKK\n",
            "Epoch 2/10\n",
            "810/810 [==============================] - 33s 40ms/step - loss: 1.8580 - accuracy: 0.4189 - val_loss: 1.8540 - val_accuracy: 0.4195\n",
            "MAKKKLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLAAAAAAAKKKKKKKK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# After GAN is trained\n",
        "def generate_sequences(generator, latent_dim, num_sequences):\n",
        "    noise = np.random.normal(0, 1, (num_sequences, latent_dim))\n",
        "    generated_sequences = generator.predict(noise, verbose=0)\n",
        "    return generated_sequences"
      ],
      "metadata": {
        "id": "hlqFCOxXx433"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_sequences=10\n",
        "generated_seqs = generate_sequences(generator, latent_dim, num_sequences=num_sequences)"
      ],
      "metadata": {
        "id": "eCogvdXx2I0V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator.save(\"AMPLify-Feedback/model_weights/PeptideGenerator.keras\")"
      ],
      "metadata": {
        "id": "-A2qBhPPUYPL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# np.save(\"/content/AMPLify-Feedback/processed_data/GAN_seq/generated_seqs_10\",generated_seqs)"
      ],
      "metadata": {
        "id": "CIjPycwJ3Fbz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert to One_hot\n",
        "# generated_seqs_one_hot = tf.one_hot(generated_seqs.squeeze(), depth=43)\n",
        "# np.save(\"/content/AMPLify-Feedback/processed_data/GAN_seq/generated_seqs_one_hot_10\",generated_seqs_one_hot)"
      ],
      "metadata": {
        "id": "i-sU4iUtFO51"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**GAN**"
      ],
      "metadata": {
        "id": "PZNppTZBwYnJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/AvonYangXX1/AMPLify-Feedback.git\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import os"
      ],
      "metadata": {
        "id": "BT9cm0MDt_N8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d677216-394f-4eef-ca99-292e30949f52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'AMPLify-Feedback'...\n",
            "remote: Enumerating objects: 469, done.\u001b[K\n",
            "remote: Counting objects: 100% (118/118), done.\u001b[K\n",
            "remote: Compressing objects: 100% (73/73), done.\u001b[K\n",
            "remote: Total 469 (delta 60), reused 97 (delta 45), pack-reused 351\u001b[K\n",
            "Receiving objects: 100% (469/469), 204.06 MiB | 16.13 MiB/s, done.\n",
            "Resolving deltas: 100% (227/227), done.\n",
            "Updating files: 100% (94/94), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generator\n",
        "def build_generator(seq_length, depth, latent_dim):\n",
        "    inputs0 = layers.Input(shape=(latent_dim,), name=\"Input0\")\n",
        "    x = layers.Dense(256, activation='relu', name=\"Dense0\")(inputs0)\n",
        "    x = layers.BatchNormalization(name=\"Norm0\")(x)\n",
        "    x = layers.Dense(256, activation='relu', name=\"Dense1\")(x)\n",
        "    x = layers.BatchNormalization(name=\"Norm1\")(x)\n",
        "    x = layers.Dense(256, activation='relu', name=\"Dense2\")(x)\n",
        "    x = layers.BatchNormalization(name=\"Norm2\")(x)\n",
        "    x = layers.Dense(256, activation='relu', name=\"Dense3\")(x)\n",
        "    x = layers.BatchNormalization(name=\"Norm3\")(x)\n",
        "    x = layers.Dense(256, activation='relu', name=\"Dense4\")(x)\n",
        "    x = layers.Dense(seq_length*depth, activation='linear', name=\"DenseResize\")(x)\n",
        "    x = layers.Reshape((seq_length, depth), name=\"Reshape\")(x)\n",
        "    # x = layers.RepeatVector(seq_length, name=\"RepeatVector\")(x)\n",
        "    # x = layers.LSTM(256, return_sequences=True, name=\"GRU0\")(x)\n",
        "    x = layers.Dense(depth, activation=\"softmax\", name=\"Output\")(x)\n",
        "    model = tf.keras.models.Model(inputs=inputs0, outputs=x)\n",
        "    return model"
      ],
      "metadata": {
        "id": "Ghzvubkvwaco"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Discriminator\n",
        "def build_discriminator(seq_length, depth):\n",
        "    model = tf.keras.Sequential(name=\"discriminator\")\n",
        "    model.add(layers.Conv1D(32, 5, name=\"Conv1D\"))\n",
        "    model.add(layers.Flatten(name=\"Flatten\"))\n",
        "    model.add(layers.Dense(512, activation='relu', name=\"Dense0\"))\n",
        "    model.add(layers.Dropout(0.3, name=\"Dropout\"))\n",
        "    model.add(layers.Dense(256, activation='relu', name=\"Dense1\"))\n",
        "    model.add(layers.Dense(1, activation='sigmoid', name=\"Output\"))\n",
        "    return model"
      ],
      "metadata": {
        "id": "QMkiH1dWwe16"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GAN\n",
        "def compile_gan(generator, discriminator):\n",
        "    discriminator.compile(loss='binary_crossentropy',\n",
        "                          optimizer='adam',\n",
        "                          metrics=[tf.keras.metrics.FalsePositives(),\n",
        "                                   tf.keras.metrics.FalseNegatives()])\n",
        "    discriminator.trainable = False\n",
        "    gan_input0 = layers.Input(shape=(latent_dim,))\n",
        "    gan_output = discriminator(generator(gan_input0))\n",
        "    gan = tf.keras.Model(gan_input0, gan_output)\n",
        "    gan.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(1e-4))\n",
        "    return gan"
      ],
      "metadata": {
        "id": "uPTCrWg-wpBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aa_vocal = np.load(\"AMPLify-Feedback/model_weights/SeqTV_vocal.npy\")\n",
        "pep_decoder = tf.keras.layers.StringLookup(vocabulary=aa_vocal[1:], invert=True, oov_token='')"
      ],
      "metadata": {
        "id": "bZwIUT4nThDJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_gan(generator, discriminator, gan, path, epochs, batch_size, latent_dim, demo_noise):\n",
        "    for epoch in range(epochs):\n",
        "        files = os.listdir(path)\n",
        "        for file in files:\n",
        "            seq = np.load(f\"{path}/{file}\", allow_pickle=True)\n",
        "            seq = tf.one_hot(seq.squeeze(), depth=43)\n",
        "            total_d_loss = 0\n",
        "            total_g_loss = 0\n",
        "            num_batches = int(seq.shape[0] / batch_size)\n",
        "            for i in range(0, seq.shape[0], batch_size):\n",
        "                real_sequences = seq[i:i + batch_size]\n",
        "                current_batch_size = real_sequences.shape[0]\n",
        "\n",
        "                # Generate Fake sequence\n",
        "                noise = (np.random.rand(current_batch_size, latent_dim)-0.5)*2\n",
        "                generated_sequences = generator.predict(noise, verbose=0)\n",
        "\n",
        "                # Labels for real and fake data\n",
        "                real_labels = np.ones((current_batch_size, 1))\n",
        "                fake_labels = np.zeros((current_batch_size, 1))\n",
        "\n",
        "                # Train discriminator\n",
        "                discriminator.trainable = True\n",
        "                d_loss_real = discriminator.train_on_batch(real_sequences, real_labels)\n",
        "                d_loss_fake = discriminator.train_on_batch(generated_sequences, fake_labels)\n",
        "                d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "                discriminator.trainable = False\n",
        "\n",
        "                # Train generator\n",
        "                g_loss = gan.train_on_batch(noise, np.ones((current_batch_size, 1)))\n",
        "\n",
        "                total_d_loss += d_loss\n",
        "                total_g_loss += g_loss\n",
        "                # print(f\"Epoch {epoch+1}/{epochs}; {file}; Batch {i}/{num_batches}; FP {d_loss[1]/current_batch_size:.4f}; FN {d_loss[2]/current_batch_size:.4f}; G_loss {g_loss:.4f}\")\n",
        "\n",
        "            demo_seq = generator(demo_noise)\n",
        "            demo_seq = tf.math.argmax(demo_seq, axis=2)\n",
        "            demo_seq = pep_decoder(demo_seq).numpy().astype('str')\n",
        "            demo_seq = [\"\".join(chars) for chars in demo_seq]\n",
        "            print(demo_seq[0])\n",
        "            print(f\"Epoch {epoch+1}/{epochs}; FP {total_d_loss[1]/seq.shape[0]:.4f}; FN {total_d_loss[2]/seq.shape[0]:.4f}; G_Loss {total_g_loss/num_batches:.4f}\")\n",
        "            del seq\n",
        "            # generator.save(f\"drive/MyDrive/MIT687/Generator.keras\")\n",
        "            # discriminator.save(f\"drive/MyDrive/MIT687/Discriminator.keras\")"
      ],
      "metadata": {
        "id": "cpbOvr8Qw9g3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_dim = 2\n",
        "seq_length = 190\n",
        "depth = 43\n",
        "path = \"AMPLify-Feedback/processed_data/gan_train_data\"\n",
        "np.random.seed(8701)\n",
        "demo_noise = noise = (np.random.rand(1, latent_dim)-0.5)*2\n",
        "\n",
        "generator = build_generator(seq_length, depth, latent_dim)\n",
        "discriminator = build_discriminator(seq_length,depth)\n",
        "gan = compile_gan(generator, discriminator)"
      ],
      "metadata": {
        "id": "Vg8qm4COcKOj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train GAN\n",
        "train_gan(generator, discriminator, gan, path, epochs=2, batch_size=22, latent_dim=latent_dim, demo_noise=demo_noise)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEbCug03xJk0",
        "outputId": "d3c4ef06-cac7-412d-94da-5aa870adc168"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MCIYSIEVVRILIEEKEKKTIASLKSSEIGIKEEKISRASISRERRIEEIIRESEKEISFTGIRPISKALEVAIEEITYIIPIK\n",
            "Epoch 1/2; FP 0.0044; FN 0.0022; G_Loss 4.0894\n",
            "MAKLLALTVAALVKIGVVLGAALILALLAVLVQQLKRSSSKRLRQSAREGDLLALETALLDNATTGATELSLVAILVISIVELAGVESGVDGGRTDGVSLLLIGLLRAKLSLRSA\n",
            "Epoch 1/2; FP 0.0043; FN 0.0055; G_Loss 10.9583\n",
            "MSNNLVGGGTLVKELNLELLELKEEAAKRVLGVGSSGLNKGLLLGVIGGNLEEGFTGGVVLLLNYTDGKGGGEKLDVETFLKIQTGEVDEENGGDGGFGELGEIGGGRDNEE\n",
            "Epoch 1/2; FP 0.0073; FN 0.0152; G_Loss 5.4502\n",
            "MSQRVQSLVLLVVLLLLQLQFDLSRALLLLEQRLQSLLVALAEKNQLLQLSSLLLQQLQLCQSCLQSQRKLISGGNLFSDVVEKKGLEGVLNGSQLLN\n",
            "Epoch 1/2; FP 0.0060; FN 0.0095; G_Loss 6.6378\n",
            "MSKETSTGIDDVETKRIVSTEELTTYTVLEENVTNVETVSVASETDKLTTNYVQGNTDTTTVVGVTETDATRTGDESYSVQSERGLCQ\n",
            "Epoch 1/2; FP 0.0048; FN 0.0067; G_Loss 6.9888\n",
            "MSGGLLSEASVLSERLSREVTDVADWSSDLSELCGLSGLHKSCVKEV\n",
            "Epoch 1/2; FP 0.0047; FN 0.0055; G_Loss 8.2052\n",
            "MSLKSACNTAAIIAALIFAHKESGSQESSKIFNASL\n",
            "Epoch 1/2; FP 0.0039; FN 0.0049; G_Loss 8.4688\n",
            "SYPTIASGRIAILLGGVALGSYAIGRFVSRVV\n",
            "Epoch 1/2; FP 0.0033; FN 0.0037; G_Loss 9.1144\n",
            "GFVPIDLKGGTGVARPKVILPLKVFFGAFGELFVDFHLVEVFIIGY\n",
            "Epoch 1/2; FP 0.0036; FN 0.0051; G_Loss 9.4442\n",
            "AKTILFSIILLISV\n",
            "Epoch 1/2; FP 0.0034; FN 0.0047; G_Loss 10.4576\n",
            "QNVQKLIHIM\n",
            "Epoch 1/2; FP 0.0014; FN 0.0044; G_Loss 8.6940\n",
            "GLKKQLMKKRL\n",
            "Epoch 1/2; FP 0.0024; FN 0.0044; G_Loss 9.4920\n",
            "GLVGLLVP\n",
            "Epoch 2/2; FP 0.0016; FN 0.0040; G_Loss 9.1442\n",
            "LSHKKFSP\n",
            "Epoch 2/2; FP 0.0020; FN 0.0036; G_Loss 9.7026\n",
            "PLSLI\n",
            "Epoch 2/2; FP 0.0015; FN 0.0049; G_Loss 7.5486\n",
            "XNHHKFIFFG\n",
            "Epoch 2/2; FP 0.0017; FN 0.0053; G_Loss 7.9358\n",
            "EGI\n",
            "Epoch 2/2; FP 0.0014; FN 0.0037; G_Loss 9.1106\n",
            "IILDLI\n",
            "Epoch 2/2; FP 0.0014; FN 0.0029; G_Loss 10.4126\n",
            "KLDLKKVKCKKGN\n",
            "Epoch 2/2; FP 0.0013; FN 0.0040; G_Loss 8.3470\n",
            "APNG\n",
            "Epoch 2/2; FP 0.0006; FN 0.0037; G_Loss 8.1288\n",
            "MEKVALKLRK\n",
            "Epoch 2/2; FP 0.0010; FN 0.0035; G_Loss 8.3459\n",
            "KLKKKLKKRL\n",
            "Epoch 2/2; FP 0.0018; FN 0.0043; G_Loss 7.4694\n",
            "EFKCILQKFKL\n",
            "Epoch 2/2; FP 0.0011; FN 0.0048; G_Loss 7.3577\n",
            "DALKLKF\n",
            "Epoch 2/2; FP 0.0014; FN 0.0046; G_Loss 7.3206\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# After GAN is trained\n",
        "def generate_sequences(generator, latent_dim, num_sequences):\n",
        "    noise = (np.random.rand(num_sequences, latent_dim)-0.5)*2\n",
        "    generated_sequences = generator.predict(noise, verbose=0)\n",
        "    return onehot2seq(generated_sequences)\n",
        "\n",
        "def onehot2seq(onehot):\n",
        "    demo_seq = tf.math.argmax(onehot, axis=2)\n",
        "    demo_seq = pep_decoder(demo_seq).numpy().astype('str')\n",
        "    demo_seq = [\"\".join(chars) for chars in demo_seq]\n",
        "    return demo_seq"
      ],
      "metadata": {
        "id": "hlqFCOxXx433"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_sequences=10\n",
        "generated_seqs = generate_sequences(generator, latent_dim, num_sequences=num_sequences)\n",
        "generated_seqs"
      ],
      "metadata": {
        "id": "eCogvdXx2I0V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bc13fd8-ff59-43fc-b4ac-741e1a6d901c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['AVTVSLDLK',\n",
              " 'DVLDFIF',\n",
              " 'AVTVSLDLK',\n",
              " 'DVLDPIF',\n",
              " 'EVGALEGKQKKLAPK',\n",
              " 'DVGALDGMFAL',\n",
              " 'EVGALEGKkKKLAK',\n",
              " 'DVLDTI',\n",
              " 'AVTVSLDLK',\n",
              " 'AVRRGDRFH']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generator.save(\"/content/AMPLify-Feedback-main/model_weights/PeptideGenerator_new.keras\")\n",
        "discriminator.save(\"/content/AMPLify-Feedback-main/model_weights/PeptideDiscriminator_new.keras\")"
      ],
      "metadata": {
        "id": "-A2qBhPPUYPL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# np.save(\"/content/AMPLify-Feedback/processed_data/GAN_seq/generated_seqs_10\",generated_seqs)"
      ],
      "metadata": {
        "id": "CIjPycwJ3Fbz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert to One_hot\n",
        "# generated_seqs_one_hot = tf.one_hot(generated_seqs.squeeze(), depth=43)\n",
        "# np.save(\"/content/AMPLify-Feedback/processed_data/GAN_seq/generated_seqs_one_hot_10\",generated_seqs_one_hot)"
      ],
      "metadata": {
        "id": "i-sU4iUtFO51"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Un8Vus9RfeSa",
        "outputId": "c4e0bb89-5092-4a99-dc5d-bf5687b5ba31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'AMPLify-Feedback' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/adcollin/AMPLify-Feedback.git\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generator = tf.keras.models.load_model('AMPLify-Feedback/model_weights/PeptideGenerator.keras')"
      ],
      "metadata": {
        "id": "0dUXRksXfmC_"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7tSERKUhWJI",
        "outputId": "d5da1bdc-1fe8-4b39-fd46-69983c8883ff"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_17\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " Input1 (InputLayer)         [(None, 326)]                0         []                            \n",
            "                                                                                                  \n",
            " Input0 (InputLayer)         [(None, 10)]                 0         []                            \n",
            "                                                                                                  \n",
            " Input1Transform (Dense)     (None, 10)                   3270      ['Input1[0][0]']              \n",
            "                                                                                                  \n",
            " Concat (Concatenate)        (None, 20)                   0         ['Input0[0][0]',              \n",
            "                                                                     'Input1Transform[0][0]']     \n",
            "                                                                                                  \n",
            " Dense0 (Dense)              (None, 256)                  5376      ['Concat[0][0]']              \n",
            "                                                                                                  \n",
            " BatchNorm0 (BatchNormaliza  (None, 256)                  1024      ['Dense0[0][0]']              \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " DenseResize (Dense)         (None, 1900)                 488300    ['BatchNorm0[0][0]']          \n",
            "                                                                                                  \n",
            " Reshape (Reshape)           (None, 190, 10)              0         ['DenseResize[0][0]']         \n",
            "                                                                                                  \n",
            " GRU0 (GRU)                  (None, 190, 256)             205824    ['Reshape[0][0]']             \n",
            "                                                                                                  \n",
            " Output (Dense)              (None, 190, 43)              11051     ['GRU0[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 714845 (2.73 MB)\n",
            "Trainable params: 714333 (2.72 MB)\n",
            "Non-trainable params: 512 (2.00 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator = tf.keras.models.load_model('AMPLify-Feedback/model_weights/PeptideDiscriminator.keras')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0uod60_0zC0",
        "outputId": "cd356098-1fd0-44b2-a838-b4ad9ce8964a"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Skipping variable loading for optimizer 'Adam', because it has 1 variables whereas the saved optimizer has 13 variables. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator.summary()"
      ],
      "metadata": {
        "id": "U-gpnXH005KM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17cc3cda-ffd9-4aff-9c62-096699314e98"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"discriminator\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Flatten (Flatten)           (None, 8170)              0         \n",
            "                                                                 \n",
            " Dense0 (Dense)              (None, 512)               4183552   \n",
            "                                                                 \n",
            " Dropout (Dropout)           (None, 512)               0         \n",
            "                                                                 \n",
            " Dense1 (Dense)              (None, 256)               131328    \n",
            "                                                                 \n",
            " Output (Dense)              (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4315137 (16.46 MB)\n",
            "Trainable params: 0 (0.00 Byte)\n",
            "Non-trainable params: 4315137 (16.46 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_oracle():\n",
        "    inputs0 = tf.keras.layers.Input((190,43),name=\"SeqInput\")\n",
        "    inputs1 = tf.keras.layers.Input((326,),name=\"StateInput\")\n",
        "    x = tf.keras.layers.Conv1D(128, 5, activation='relu', name=\"Conv1D_0\")(inputs0) # kernel_size=5 works well\n",
        "    x = tf.keras.layers.Conv1D(128, 5, activation='relu', name=\"Conv1D_1\")(x) # Just two layers work better\n",
        "    x = tf.keras.layers.Flatten(name=\"Flatten_0\")(x)\n",
        "    x = tf.keras.layers.Dense(512, activation=\"relu\", name=\"LearnSeqDense_0\")(x)\n",
        "    x = tf.keras.layers.Concatenate(axis=1, name=\"Concat\")([x, inputs1])\n",
        "    x = tf.keras.layers.Dense(1024, activation=\"relu\", name=\"LearnConcatDense_0\")(x)\n",
        "    x = tf.keras.layers.LayerNormalization(name=\"LayerNorm_0\")(x)\n",
        "    x = tf.keras.layers.Dense(512, activation=\"relu\", name=\"LearnConcatDense_1\")(x)\n",
        "    x = tf.keras.layers.LayerNormalization(name=\"LayerNorm_1\")(x)\n",
        "    x = tf.keras.layers.Dense(1, activation=\"linear\", name=\"Output\")(x)\n",
        "    model = tf.keras.models.Model([inputs0, inputs1], x, name=\"MICPredictor\")\n",
        "    return model"
      ],
      "metadata": {
        "id": "KK6BbgTkf3Nb"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "oracle = create_oracle()\n",
        "path = \"AMPLify-Feedback/model_weights/MICPredictor\"\n",
        "for i, layer in enumerate(oracle.layers):\n",
        "    weights = np.load(f\"{path}/layer_{i}_weights.npy\", allow_pickle=True)\n",
        "    layer.set_weights(weights)"
      ],
      "metadata": {
        "id": "D977mDVFggf1"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "oracle.summary()"
      ],
      "metadata": {
        "id": "EyQM0g3330Vb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "913d023c-8f66-4ec7-8fa9-e00792f03ad9"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"MICPredictor\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " SeqInput (InputLayer)       [(None, 190, 43)]            0         []                            \n",
            "                                                                                                  \n",
            " Conv1D_0 (Conv1D)           (None, 186, 128)             27648     ['SeqInput[0][0]']            \n",
            "                                                                                                  \n",
            " Conv1D_1 (Conv1D)           (None, 182, 128)             82048     ['Conv1D_0[0][0]']            \n",
            "                                                                                                  \n",
            " Flatten_0 (Flatten)         (None, 23296)                0         ['Conv1D_1[0][0]']            \n",
            "                                                                                                  \n",
            " LearnSeqDense_0 (Dense)     (None, 512)                  1192806   ['Flatten_0[0][0]']           \n",
            "                                                          4                                       \n",
            "                                                                                                  \n",
            " StateInput (InputLayer)     [(None, 326)]                0         []                            \n",
            "                                                                                                  \n",
            " Concat (Concatenate)        (None, 838)                  0         ['LearnSeqDense_0[0][0]',     \n",
            "                                                                     'StateInput[0][0]']          \n",
            "                                                                                                  \n",
            " LearnConcatDense_0 (Dense)  (None, 1024)                 859136    ['Concat[0][0]']              \n",
            "                                                                                                  \n",
            " LayerNorm_0 (LayerNormaliz  (None, 1024)                 2048      ['LearnConcatDense_0[0][0]']  \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " LearnConcatDense_1 (Dense)  (None, 512)                  524800    ['LayerNorm_0[0][0]']         \n",
            "                                                                                                  \n",
            " LayerNorm_1 (LayerNormaliz  (None, 512)                  1024      ['LearnConcatDense_1[0][0]']  \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " Output (Dense)              (None, 1)                    513       ['LayerNorm_1[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 13425281 (51.21 MB)\n",
            "Trainable params: 13425281 (51.21 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GAN\n",
        "def compile_gan(generator, discriminator):\n",
        "    discriminator.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    discriminator.trainable = False\n",
        "    gan_input0 = layers.Input(shape=(latent_dim,))\n",
        "    gan_input1 = layers.Input(shape=(326,))\n",
        "    gan_output = discriminator(generator([gan_input0, gan_input1]))\n",
        "    gan = tf.keras.Model([gan_input0, gan_input1], gan_output)\n",
        "    gan.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "    return gan"
      ],
      "metadata": {
        "id": "ULeDwzAP0pxM"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_sequences(generator, latent_dim, num_sequences):\n",
        "    noise = np.random.normal(0, 1, (num_sequences, latent_dim))\n",
        "    bacteria = []\n",
        "    for i in range(num_sequences):\n",
        "      bacterium = np.zeros(326)\n",
        "      bacterium[np.random.randint(0, 326)]=1\n",
        "      bacteria.append([bacterium])\n",
        "    bacteria = np.concatenate(bacteria, axis=0)\n",
        "    generated_sequences = generator.predict([noise, bacteria])\n",
        "    return generated_sequences, bacteria"
      ],
      "metadata": {
        "id": "Fo2d1_s9hSs0"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fit_gan(generator, discriminator, gan, seq_train, state_train, labels, epochs, batch_size, latent_dim):\n",
        "    for epoch in range(epochs):\n",
        "        for i in range(0, seq_train.shape[0], batch_size):\n",
        "            sequences = seq_train[i:i + batch_size]\n",
        "            state_train_batch = state_train[i:i + batch_size]\n",
        "            current_batch_size = sequences.shape[0]\n",
        "\n",
        "            # Train discriminator\n",
        "            discriminator.trainable = True\n",
        "            d_loss = discriminator.train_on_batch(sequences, labels)\n",
        "            discriminator.trainable = False\n",
        "\n",
        "            # Train generator\n",
        "            noise = np.random.normal(0, 1, (current_batch_size, latent_dim))\n",
        "            g_loss = gan.train_on_batch([noise, state_train_batch], labels)\n",
        "\n",
        "            # Print the progress\n",
        "            print(f\"Epoch {epoch+1}/{epochs}, Batch {i//batch_size+1}, Discriminator Loss: {d_loss}, Generator Loss: {g_loss}\")"
      ],
      "metadata": {
        "id": "L6ofmOCju_lt"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def feedback_loop_prediction(prediction, threshold):\n",
        "  loop_prediction = np.zeros((prediction.shape[0], 1))\n",
        "  for i in range (prediction.shape[0]):\n",
        "    if prediction[i] < threshold:\n",
        "      loop_prediction[i] = 1\n",
        "  return loop_prediction"
      ],
      "metadata": {
        "id": "c8wwXH4zzdNT"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def RL_loop(generator, discriminator, gan, oracle, num_sequences):\n",
        "  for i in range (n_iter_max) :\n",
        "    sequences, bacteria = generate_sequences(generator, latent_dim, num_sequences)\n",
        "    prediction = oracle.predict([sequences, bacteria])\n",
        "    loop_prediction = feedback_loop_prediction(prediction, math.log(100,2))\n",
        "    fit_gan(generator, discriminator, gan, sequences, bacteria, loop_prediction, epochs=5, batch_size=num_sequences, latent_dim=latent_dim)"
      ],
      "metadata": {
        "id": "wbEqlQ5xz8R4"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_dim = 10\n",
        "num_sequences = 100\n",
        "n_iter_max = 10\n",
        "\n",
        "gan = compile_gan(generator, discriminator)\n",
        "\n",
        "RL_loop(generator, discriminator, gan, oracle, num_sequences)"
      ],
      "metadata": {
        "id": "P_CXFJVM3I6R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58763c6c-7657-4225-f987-61f25780ef5d"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 65ms/step\n",
            "4/4 [==============================] - 0s 29ms/step\n",
            "Epoch 1/5, Batch 1, Discriminator Loss: [1.193461537361145, 0.36000001430511475], Generator Loss: 1.1725174188613892\n",
            "Epoch 2/5, Batch 1, Discriminator Loss: [1.1837159395217896, 0.3400000035762787], Generator Loss: 1.0413657426834106\n",
            "Epoch 3/5, Batch 1, Discriminator Loss: [1.2448168992996216, 0.3100000023841858], Generator Loss: 1.060624361038208\n",
            "Epoch 4/5, Batch 1, Discriminator Loss: [1.126537799835205, 0.3799999952316284], Generator Loss: 0.919628918170929\n",
            "Epoch 5/5, Batch 1, Discriminator Loss: [1.2678349018096924, 0.30000001192092896], Generator Loss: 0.577129602432251\n",
            "4/4 [==============================] - 0s 106ms/step\n",
            "4/4 [==============================] - 0s 44ms/step\n",
            "Epoch 1/5, Batch 1, Discriminator Loss: [0.6505067348480225, 0.7200000286102295], Generator Loss: 0.7472743988037109\n",
            "Epoch 2/5, Batch 1, Discriminator Loss: [0.5603952407836914, 0.7900000214576721], Generator Loss: 0.8301504254341125\n",
            "Epoch 3/5, Batch 1, Discriminator Loss: [0.6779341697692871, 0.7300000190734863], Generator Loss: 0.6682521104812622\n",
            "Epoch 4/5, Batch 1, Discriminator Loss: [0.6395621299743652, 0.7599999904632568], Generator Loss: 0.6666396856307983\n",
            "Epoch 5/5, Batch 1, Discriminator Loss: [0.6448254585266113, 0.6899999976158142], Generator Loss: 0.722343385219574\n",
            "4/4 [==============================] - 0s 66ms/step\n",
            "4/4 [==============================] - 0s 29ms/step\n",
            "Epoch 1/5, Batch 1, Discriminator Loss: [0.3923613727092743, 0.8799999952316284], Generator Loss: 0.5535485744476318\n",
            "Epoch 2/5, Batch 1, Discriminator Loss: [0.42453277111053467, 0.8100000023841858], Generator Loss: 0.6102147698402405\n",
            "Epoch 3/5, Batch 1, Discriminator Loss: [0.37607964873313904, 0.8799999952316284], Generator Loss: 0.6521656513214111\n",
            "Epoch 4/5, Batch 1, Discriminator Loss: [0.3450864851474762, 0.8299999833106995], Generator Loss: 0.6534634232521057\n",
            "Epoch 5/5, Batch 1, Discriminator Loss: [0.35898783802986145, 0.8199999928474426], Generator Loss: 0.5540610551834106\n",
            "4/4 [==============================] - 0s 104ms/step\n",
            "4/4 [==============================] - 0s 39ms/step\n",
            "Epoch 1/5, Batch 1, Discriminator Loss: [0.21093173325061798, 0.9300000071525574], Generator Loss: 0.41507217288017273\n",
            "Epoch 2/5, Batch 1, Discriminator Loss: [0.23611406981945038, 0.9200000166893005], Generator Loss: 0.17201730608940125\n",
            "Epoch 3/5, Batch 1, Discriminator Loss: [0.23607006669044495, 0.9100000262260437], Generator Loss: 0.4018044173717499\n",
            "Epoch 4/5, Batch 1, Discriminator Loss: [0.35058262944221497, 0.8399999737739563], Generator Loss: 0.25862908363342285\n",
            "Epoch 5/5, Batch 1, Discriminator Loss: [0.20763570070266724, 0.9100000262260437], Generator Loss: 0.2777113616466522\n",
            "4/4 [==============================] - 0s 110ms/step\n",
            "4/4 [==============================] - 0s 46ms/step\n",
            "Epoch 1/5, Batch 1, Discriminator Loss: [0.5541425943374634, 0.8899999856948853], Generator Loss: 0.6096517443656921\n",
            "Epoch 2/5, Batch 1, Discriminator Loss: [0.5891408324241638, 0.8600000143051147], Generator Loss: 0.6339161992073059\n",
            "Epoch 3/5, Batch 1, Discriminator Loss: [0.5102701783180237, 0.8799999952316284], Generator Loss: 0.6461552977561951\n",
            "Epoch 4/5, Batch 1, Discriminator Loss: [0.5469990968704224, 0.8600000143051147], Generator Loss: 0.4667130708694458\n",
            "Epoch 5/5, Batch 1, Discriminator Loss: [0.533116340637207, 0.8799999952316284], Generator Loss: 0.49716052412986755\n",
            "4/4 [==============================] - 0s 74ms/step\n",
            "4/4 [==============================] - 0s 29ms/step\n",
            "Epoch 1/5, Batch 1, Discriminator Loss: [0.3409785330295563, 0.8999999761581421], Generator Loss: 0.431660920381546\n",
            "Epoch 2/5, Batch 1, Discriminator Loss: [0.4084111452102661, 0.8999999761581421], Generator Loss: 0.42275214195251465\n",
            "Epoch 3/5, Batch 1, Discriminator Loss: [0.43626606464385986, 0.8899999856948853], Generator Loss: 0.45980602502822876\n",
            "Epoch 4/5, Batch 1, Discriminator Loss: [0.4569306969642639, 0.8600000143051147], Generator Loss: 0.48236221075057983\n",
            "Epoch 5/5, Batch 1, Discriminator Loss: [0.506736695766449, 0.9200000166893005], Generator Loss: 0.5015210509300232\n",
            "4/4 [==============================] - 0s 73ms/step\n",
            "4/4 [==============================] - 0s 31ms/step\n",
            "Epoch 1/5, Batch 1, Discriminator Loss: [0.4679866433143616, 0.9100000262260437], Generator Loss: 0.6020404696464539\n",
            "Epoch 2/5, Batch 1, Discriminator Loss: [0.6315107941627502, 0.9100000262260437], Generator Loss: 0.6746559143066406\n",
            "Epoch 3/5, Batch 1, Discriminator Loss: [0.4661529064178467, 0.8899999856948853], Generator Loss: 0.7421311736106873\n",
            "Epoch 4/5, Batch 1, Discriminator Loss: [0.5925740599632263, 0.9100000262260437], Generator Loss: 0.524153470993042\n",
            "Epoch 5/5, Batch 1, Discriminator Loss: [0.6517647504806519, 0.8999999761581421], Generator Loss: 0.5089514255523682\n",
            "4/4 [==============================] - 0s 92ms/step\n",
            "4/4 [==============================] - 0s 27ms/step\n",
            "Epoch 1/5, Batch 1, Discriminator Loss: [0.3645704388618469, 0.8700000047683716], Generator Loss: 0.32882121205329895\n",
            "Epoch 2/5, Batch 1, Discriminator Loss: [0.3140440583229065, 0.8999999761581421], Generator Loss: 0.2774994969367981\n",
            "Epoch 3/5, Batch 1, Discriminator Loss: [0.3152109980583191, 0.8899999856948853], Generator Loss: 0.29618752002716064\n",
            "Epoch 4/5, Batch 1, Discriminator Loss: [0.2947360873222351, 0.949999988079071], Generator Loss: 0.332072377204895\n",
            "Epoch 5/5, Batch 1, Discriminator Loss: [0.33018457889556885, 0.8899999856948853], Generator Loss: 0.3973503112792969\n",
            "4/4 [==============================] - 0s 69ms/step\n",
            "4/4 [==============================] - 0s 29ms/step\n",
            "Epoch 1/5, Batch 1, Discriminator Loss: [0.3586335778236389, 0.9100000262260437], Generator Loss: 0.4110371470451355\n",
            "Epoch 2/5, Batch 1, Discriminator Loss: [0.3672102689743042, 0.8799999952316284], Generator Loss: 0.3851446211338043\n",
            "Epoch 3/5, Batch 1, Discriminator Loss: [0.39172443747520447, 0.8600000143051147], Generator Loss: 0.47588053345680237\n",
            "Epoch 4/5, Batch 1, Discriminator Loss: [0.402831107378006, 0.8899999856948853], Generator Loss: 0.45759132504463196\n",
            "Epoch 5/5, Batch 1, Discriminator Loss: [0.4839276373386383, 0.8500000238418579], Generator Loss: 0.34061649441719055\n",
            "4/4 [==============================] - 0s 62ms/step\n",
            "4/4 [==============================] - 0s 28ms/step\n",
            "Epoch 1/5, Batch 1, Discriminator Loss: [0.6024912595748901, 0.7900000214576721], Generator Loss: 0.4804365038871765\n",
            "Epoch 2/5, Batch 1, Discriminator Loss: [0.49660196900367737, 0.8600000143051147], Generator Loss: 0.6055903434753418\n",
            "Epoch 3/5, Batch 1, Discriminator Loss: [0.5313513278961182, 0.8799999952316284], Generator Loss: 0.4745222330093384\n",
            "Epoch 4/5, Batch 1, Discriminator Loss: [0.5535480976104736, 0.8299999833106995], Generator Loss: 0.6957843899726868\n",
            "Epoch 5/5, Batch 1, Discriminator Loss: [0.5542027354240417, 0.8600000143051147], Generator Loss: 0.5842769742012024\n"
          ]
        }
      ]
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Un8Vus9RfeSa",
        "outputId": "58f83f93-2bcb-4180-d8d3-f7f758408b67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'AMPLify-Feedback'...\n",
            "remote: Enumerating objects: 368, done.\u001b[K\n",
            "remote: Counting objects: 100% (17/17), done.\u001b[K\n",
            "remote: Compressing objects: 100% (12/12), done.\u001b[K\n",
            "remote: Total 368 (delta 5), reused 14 (delta 5), pack-reused 351\u001b[K\n",
            "Receiving objects: 100% (368/368), 99.94 MiB | 7.58 MiB/s, done.\n",
            "Resolving deltas: 100% (172/172), done.\n",
            "Updating files: 100% (72/72), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/adcollin/AMPLify-Feedback.git\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generator = tf.keras.models.load_model('AMPLify-Feedback/model_weights/PeptideGenerator.keras')"
      ],
      "metadata": {
        "id": "0dUXRksXfmC_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7tSERKUhWJI",
        "outputId": "31a5d0b4-425c-480c-f6d6-a571216d1bcb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_17\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " Input1 (InputLayer)         [(None, 326)]                0         []                            \n",
            "                                                                                                  \n",
            " Input0 (InputLayer)         [(None, 10)]                 0         []                            \n",
            "                                                                                                  \n",
            " Input1Transform (Dense)     (None, 10)                   3270      ['Input1[0][0]']              \n",
            "                                                                                                  \n",
            " Concat (Concatenate)        (None, 20)                   0         ['Input0[0][0]',              \n",
            "                                                                     'Input1Transform[0][0]']     \n",
            "                                                                                                  \n",
            " Dense0 (Dense)              (None, 256)                  5376      ['Concat[0][0]']              \n",
            "                                                                                                  \n",
            " BatchNorm0 (BatchNormaliza  (None, 256)                  1024      ['Dense0[0][0]']              \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " DenseResize (Dense)         (None, 1900)                 488300    ['BatchNorm0[0][0]']          \n",
            "                                                                                                  \n",
            " Reshape (Reshape)           (None, 190, 10)              0         ['DenseResize[0][0]']         \n",
            "                                                                                                  \n",
            " GRU0 (GRU)                  (None, 190, 256)             205824    ['Reshape[0][0]']             \n",
            "                                                                                                  \n",
            " Output (Dense)              (None, 190, 43)              11051     ['GRU0[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 714845 (2.73 MB)\n",
            "Trainable params: 714333 (2.72 MB)\n",
            "Non-trainable params: 512 (2.00 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator = tf.keras.models.load_model('AMPLify-Feedback/model_weights/discriminator.keras')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "u0uod60_0zC0",
        "outputId": "8a2e5434-487e-43dd-88fd-385c771acea0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-2145a777693d>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdiscriminator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'AMPLify-Feedback/model_weights/discriminator.keras'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_api.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0;31m# Legacy case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m     return legacy_sm_saving_lib.load_model(\n\u001b[0m\u001b[1;32m    263\u001b[0m         \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/legacy/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    232\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                             raise IOError(\n\u001b[0m\u001b[1;32m    235\u001b[0m                                 \u001b[0;34mf\"No file or directory found at {filepath_str}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                             )\n",
            "\u001b[0;31mOSError\u001b[0m: No file or directory found at AMPLify-Feedback/model_weights/discriminator.keras"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator.summary()"
      ],
      "metadata": {
        "id": "U-gpnXH005KM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_oracle():\n",
        "    inputs0 = tf.keras.layers.Input((190,43),name=\"SeqInput\")\n",
        "    inputs1 = tf.keras.layers.Input((326,),name=\"StateInput\")\n",
        "    x = tf.keras.layers.Conv1D(128, 5, activation='relu', name=\"Conv1D_0\")(inputs0) # kernel_size=5 works well\n",
        "    x = tf.keras.layers.Conv1D(128, 5, activation='relu', name=\"Conv1D_1\")(x) # Just two layers work better\n",
        "    x = tf.keras.layers.Flatten(name=\"Flatten_0\")(x)\n",
        "    x = tf.keras.layers.Dense(512, activation=\"relu\", name=\"LearnSeqDense_0\")(x)\n",
        "    x = tf.keras.layers.Concatenate(axis=1, name=\"Concat\")([x, inputs1])\n",
        "    x = tf.keras.layers.Dense(1024, activation=\"relu\", name=\"LearnConcatDense_0\")(x)\n",
        "    x = tf.keras.layers.LayerNormalization(name=\"LayerNorm_0\")(x)\n",
        "    x = tf.keras.layers.Dense(512, activation=\"relu\", name=\"LearnConcatDense_1\")(x)\n",
        "    x = tf.keras.layers.LayerNormalization(name=\"LayerNorm_1\")(x)\n",
        "    x = tf.keras.layers.Dense(1, activation=\"linear\", name=\"Output\")(x)\n",
        "    model = tf.keras.models.Model([inputs0, inputs1], x, name=\"MICPredictor\")\n",
        "    return model"
      ],
      "metadata": {
        "id": "KK6BbgTkf3Nb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "oracle = create_oracle()\n",
        "path = \"AMPLify-Feedback/model_weights/MICPredictor\"\n",
        "for i, layer in enumerate(oracle.layers):\n",
        "    weights = np.load(f\"{path}/layer_{i}_weights.npy\", allow_pickle=True)\n",
        "    layer.set_weights(weights)"
      ],
      "metadata": {
        "id": "D977mDVFggf1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "oracle.summary()"
      ],
      "metadata": {
        "id": "EyQM0g3330Vb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GAN\n",
        "def compile_gan(generator, discriminator):\n",
        "    discriminator.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    discriminator.trainable = False\n",
        "    gan_input0 = layers.Input(shape=(latent_dim,))\n",
        "    gan_input1 = layers.Input(shape=(326,))\n",
        "    gan_output = discriminator(generator([gan_input0, gan_input1]))\n",
        "    gan = tf.keras.Model([gan_input0, gan_input1], gan_output)\n",
        "    gan.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "    return gan"
      ],
      "metadata": {
        "id": "ULeDwzAP0pxM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_sequences(generator, latent_dim, num_sequences):\n",
        "    noise = np.random.normal(0, 1, (num_sequences, latent_dim))\n",
        "    bacteria = []\n",
        "    for i in range(num_sequences):\n",
        "      bacterium = np.zeros(326)\n",
        "      bacterium[np.random.randint(0, 326)]=1\n",
        "      bacteria.append([bacterium])\n",
        "    bacteria = np.concatenate(bacteria, axis=0)\n",
        "    generated_sequences = generator.predict([noise, bacteria])\n",
        "    return generated_sequences, bacteria"
      ],
      "metadata": {
        "id": "Fo2d1_s9hSs0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "################### if gradient approach using hallucination #####################\n",
        "def update_generator(generator, MIC):\n",
        "  learning_rate = 0.001\n",
        "  with tf.GradientTape() as tape:\n",
        "    y = tf.constant(MIC)\n",
        "  gradients = tape.gradient(y, generator.trainable_variables)\n",
        "  ####### check gradient\n",
        "  for var, g in zip(layer.trainable_variables, gradients):\n",
        "    print(f'{var.name}, shape: {g.shape}')\n",
        "  #########\n",
        "  gradients_and_vars = zip(gradients, generator.trainable_variables)\n",
        "  optimizer = tf.optimizers.Adam(learning_rate)\n",
        "  optimizer.apply_gradients(gradients_and_vars)"
      ],
      "metadata": {
        "id": "HhKqr_SGNrC4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fit_gan(generator, discriminator, gan, seq_train, state_train, labels, epochs, batch_size, latent_dim):\n",
        "    for epoch in range(epochs):\n",
        "        for i in range(0, seq_train.shape[0], batch_size):\n",
        "            sequences = seq_train[i:i + batch_size]\n",
        "            state_train_batch = state_train[i:i + batch_size]\n",
        "            current_batch_size = sequences.shape[0]\n",
        "\n",
        "            # Train discriminator\n",
        "            discriminator.trainable = True\n",
        "            d_loss = discriminator.train_on_batch(sequences, labels)\n",
        "            discriminator.trainable = False\n",
        "\n",
        "            # Train generator\n",
        "            noise = np.random.normal(0, 1, (current_batch_size, latent_dim))\n",
        "            g_loss = gan.train_on_batch([noise, state_train_batch], labels)\n",
        "\n",
        "            # Print the progress\n",
        "            print(f\"Epoch {epoch+1}/{epochs}, Batch {i//batch_size+1}, Discriminator Loss: {d_loss}, Generator Loss: {g_loss}\")"
      ],
      "metadata": {
        "id": "L6ofmOCju_lt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def feedback_loop_prediction(prediction, threshold):\n",
        "  loop_prediction = np.zeros((prediction.shape[0], 1))\n",
        "  for i in range (prediction.shape[0]):\n",
        "    if prediction[i] < threshold:\n",
        "      loop_prediction[i] = 1\n",
        "  return loop_prediction"
      ],
      "metadata": {
        "id": "c8wwXH4zzdNT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def RL_loop(generator, oracle):\n",
        "  for i in range (n_iter_max) :\n",
        "    sequences, bacteria = generate_sequences(generator, latent_dim, num_sequences)\n",
        "    prediction = oracle.predict([sequences, bacteria])\n",
        "    loop_prediction = feedback_loop_prediction(prediction, math.log(100,2))\n",
        "    seq_output = tf.one_hot(sequences.squeeze(), depth=43)\n",
        "    seq_label = tf.one_hot(loop_prediction.squeeze(), depth=43)\n",
        "    fit_gan(generator, discriminator, gan, seq_output, bacteria, seq_label, epochs=5, batch_size=32, latent_dim=latent_dim)\n",
        "\n",
        "\n",
        "\n",
        "    ################ EVALUATION METRIC\n",
        "    #generator.compile(optimizer=Adam(3e-5))\n",
        "    #generator.fit([seq_output, bacteria], seq_val)\n",
        "    #generator_update = update_generator(generator, prediction)\n",
        "    #generator.train([seq_train, bacteria], seq_train)\n",
        "\n",
        "  #return prediction"
      ],
      "metadata": {
        "id": "wbEqlQ5xz8R4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_dim = 10\n",
        "num_sequences = 100\n",
        "n_iter_max = 10\n",
        "\n",
        "gan = compile_gan(generator, discriminator)\n",
        "\n",
        "RL_loop(generator, oracle)"
      ],
      "metadata": {
        "id": "P_CXFJVM3I6R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.debugging.disable_traceback_filtering()"
      ],
      "metadata": {
        "id": "lVduArzsV3fy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
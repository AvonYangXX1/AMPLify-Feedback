{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/AvonYangXX1/AMPLify-Feedback.git\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oeShSnnkB-_P",
        "outputId": "b319c1fb-7ce6-42af-8d4a-19ee82bb33ec"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'AMPLify-Feedback'...\n",
            "remote: Enumerating objects: 106, done.\u001b[K\n",
            "remote: Counting objects: 100% (106/106), done.\u001b[K\n",
            "remote: Compressing objects: 100% (41/41), done.\u001b[K\n",
            "remote: Total 106 (delta 66), reused 98 (delta 61), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (106/106), 6.40 MiB | 2.97 MiB/s, done.\n",
            "Resolving deltas: 100% (66/66), done.\n",
            "Updating files: 100% (41/41), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.config.run_functions_eagerly(True)\n",
        "\n",
        "seq_train = np.load(\"AMPLify-Feedback/processed_data/cv/seq_train_1.npy\")\n",
        "state_train = np.load(\"AMPLify-Feedback/processed_data/cv/state_train_1.npy\")\n",
        "label_train = np.load(\"AMPLify-Feedback/processed_data/cv/label_train_1.npy\")\n",
        "seq_test = np.load(\"AMPLify-Feedback/processed_data/cv/seq_test_1.npy\")\n",
        "state_test = np.load(\"AMPLify-Feedback/processed_data/cv/state_test_1.npy\")\n",
        "label_test = np.load(\"AMPLify-Feedback/processed_data/cv/label_test_1.npy\")\n",
        "seq_train = np.expand_dims(seq_train, 2).astype(\"float32\")\n",
        "seq_test = np.expand_dims(seq_test, 2).astype(\"float32\")\n",
        "state_train = np.expand_dims(state_train, 2).astype(\"float32\")\n",
        "state_test = np.expand_dims(state_test, 2).astype(\"float32\")\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(((seq_train, state_train), label_train))\n",
        "train_dataset = train_dataset.shuffle(buffer_size=len(seq_train))\n",
        "train_dataset = train_dataset.batch(100)\n",
        "train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices(((seq_test, state_test), label_test))\n",
        "test_dataset = test_dataset.batch(100)\n",
        "test_dataset = test_dataset.prefetch(tf.data.experimental.AUTOTUNE)"
      ],
      "metadata": {
        "id": "YpUHhfy-B_Gb"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def train_step(seqs, states, labels):\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions = model(seqs, states)\n",
        "        loss = loss_function(labels, predictions)\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "    train_accuracy_metric.update_state(labels, predictions)\n",
        "    return loss\n",
        "\n",
        "@tf.function\n",
        "def val_step(seqs, states, labels):\n",
        "    predictions = model(seqs, states)\n",
        "    loss = loss_function(labels, predictions)\n",
        "    val_accuracy_metric.update_state(labels, predictions)\n",
        "    return loss"
      ],
      "metadata": {
        "id": "_qWWsywqB_Ji"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "9IJgawk8B14C"
      },
      "outputs": [],
      "source": [
        "class ActivityPredictor(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.Embed = tf.keras.models.Sequential([\n",
        "            # tf.keras.layers.Conv1D(1, 3, activation='relu', name=\"Conv1D_0\"),\n",
        "            # tf.keras.layers.Conv1D(1, 1, activation='relu', name=\"Conv1D_Fusion\"),\n",
        "            tf.keras.layers.Flatten(name=\"Flatten\"),\n",
        "            tf.keras.layers.Dense(512, activation=\"relu\", name=\"EmbedState\"),\n",
        "            # tf.keras.layers.LayerNormalization(name=\"LayerNorm_0\"),\n",
        "        ], name=\"EmbedState\")\n",
        "\n",
        "        self.cnn = tf.keras.models.Sequential([\n",
        "            tf.keras.layers.Conv1D(64, 3, activation='relu', name=\"Conv1D_0\"),\n",
        "            tf.keras.layers.Conv1D(64, 3, activation='relu', name=\"Conv1D_1\"),\n",
        "            tf.keras.layers.Conv1D(64, 3, activation='relu', name=\"Conv1D_2\"),\n",
        "            tf.keras.layers.Conv1D(64, 3, activation='relu', name=\"Conv1D_3\"),\n",
        "            tf.keras.layers.Conv1D(64, 3, activation='relu', name=\"Conv1D_4\"),\n",
        "            tf.keras.layers.Conv1D(64, 3, activation='relu', name=\"Conv1D_5\"),\n",
        "            tf.keras.layers.Conv1D(64, 3, activation='relu', name=\"Conv1D_6\"),\n",
        "            tf.keras.layers.Conv1D(1, 1, activation='relu', name=\"Conv1D_Fusion\"),\n",
        "            tf.keras.layers.Flatten(name=\"Flatten\"),\n",
        "            # tf.keras.layers.LSTM(1024, name=\"GRU_0\", return_sequences=True),\n",
        "            # tf.keras.layers.GRU(1024, name=\"GRU_1\", return_sequences=True),\n",
        "            # tf.keras.layers.GRU(128, name=\"GRU_2\", return_sequences=True),\n",
        "            # tf.keras.layers.GRU(128, name=\"GRU_3\", return_sequences=True),\n",
        "            # tf.keras.layers.LSTM(1024, name=\"GRU_4\", return_sequences=False),\n",
        "            tf.keras.layers.Dense(512, activation=\"relu\", name=\"CNN_Out\"),\n",
        "            # tf.keras.layers.LayerNormalization(name=\"LayerNorm_1\"),\n",
        "        ], name=\"cnn\")\n",
        "\n",
        "        self.fcn = tf.keras.models.Sequential([\n",
        "            tf.keras.layers.Dense(1024, activation=\"relu\", name=\"Dense_0\"),\n",
        "            tf.keras.layers.Dense(1024, activation=\"relu\", name=\"Dense_1\"),\n",
        "            tf.keras.layers.Dense(1024, activation=\"relu\", name=\"Dense_2\"),\n",
        "            tf.keras.layers.Dense(1024, activation=\"relu\", name=\"Dense_3\"),\n",
        "            tf.keras.layers.Dense(64, activation=\"relu\", name=\"Dense_4\"),\n",
        "            # tf.keras.layers.LayerNormalization(name=\"LayerNorm_3\"),\n",
        "        ], name=\"fcn\")\n",
        "        self.Output = tf.keras.layers.Dense(1, activation=\"sigmoid\", name=\"Output\")\n",
        "        # self.call_layernorm = tf.keras.layers.LayerNormalization(name=\"LayerNorm_2\")\n",
        "\n",
        "    def call(self, seq, state):\n",
        "        x0 = self.cnn(seq)\n",
        "        x1 = self.Embed(state)\n",
        "        x = tf.keras.layers.Concatenate()([x0, x1])\n",
        "        # x = self.call_layernorm(x)\n",
        "        x = self.fcn(x)\n",
        "        x = self.Output(x)\n",
        "        return x\n",
        "\n",
        "model = ActivityPredictor()\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
        "loss_function = tf.keras.losses.BinaryCrossentropy()\n",
        "train_accuracy_metric = tf.keras.metrics.BinaryAccuracy()\n",
        "val_accuracy_metric = tf.keras.metrics.BinaryAccuracy()\n",
        "model.compile(optimizer=optimizer, loss=loss_function, metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 20\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    print(f\"\\nEpoch {epoch + 1}/{EPOCHS}\")\n",
        "    print('-' * 40)\n",
        "\n",
        "    # Training Loop\n",
        "    total_loss = 0\n",
        "    num_batches = 0\n",
        "    for (batch_seqs, batch_states), batch_labels in train_dataset:\n",
        "        total_loss += train_step(batch_seqs, batch_states, batch_labels)\n",
        "        num_batches += 1\n",
        "    train_loss = total_loss / num_batches\n",
        "    train_accuracy = train_accuracy_metric.result()\n",
        "\n",
        "    # Validation Loop\n",
        "    total_val_loss = 0\n",
        "    num_val_batches = 0\n",
        "    for (batch_seqs, batch_states), batch_labels in test_dataset:\n",
        "        total_val_loss += val_step(batch_seqs, batch_states, batch_labels)\n",
        "        num_val_batches += 1\n",
        "    val_loss = total_val_loss / num_val_batches\n",
        "    val_accuracy = val_accuracy_metric.result()\n",
        "\n",
        "    # Logging Results\n",
        "    print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}\")\n",
        "    print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "    # Resetting Metrics\n",
        "    train_accuracy_metric.reset_states()\n",
        "    val_accuracy_metric.reset_states()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F31H0L07CITN",
        "outputId": "86e6670c-790a-401c-ff44-929013319f9e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/20\n",
            "----------------------------------------\n",
            "Train Loss: 0.4965, Train Accuracy: 0.4093\n",
            "Validation Loss: 0.5422, Validation Accuracy: 0.3090\n",
            "\n",
            "Epoch 2/20\n",
            "----------------------------------------\n",
            "Train Loss: 0.3874, Train Accuracy: 0.4344\n",
            "Validation Loss: 0.3637, Validation Accuracy: 0.4444\n",
            "\n",
            "Epoch 3/20\n",
            "----------------------------------------\n",
            "Train Loss: 0.3278, Train Accuracy: 0.4479\n",
            "Validation Loss: 0.3161, Validation Accuracy: 0.4394\n",
            "\n",
            "Epoch 4/20\n",
            "----------------------------------------\n",
            "Train Loss: 0.2876, Train Accuracy: 0.4609\n",
            "Validation Loss: 0.2906, Validation Accuracy: 0.4437\n",
            "\n",
            "Epoch 5/20\n",
            "----------------------------------------\n",
            "Train Loss: 0.2507, Train Accuracy: 0.4688\n",
            "Validation Loss: 0.3160, Validation Accuracy: 0.4229\n",
            "\n",
            "Epoch 6/20\n",
            "----------------------------------------\n",
            "Train Loss: 0.2251, Train Accuracy: 0.4750\n",
            "Validation Loss: 0.2433, Validation Accuracy: 0.4664\n",
            "\n",
            "Epoch 7/20\n",
            "----------------------------------------\n",
            "Train Loss: 0.2053, Train Accuracy: 0.4785\n",
            "Validation Loss: 0.2665, Validation Accuracy: 0.4764\n",
            "\n",
            "Epoch 8/20\n",
            "----------------------------------------\n",
            "Train Loss: 0.1890, Train Accuracy: 0.4815\n",
            "Validation Loss: 0.2200, Validation Accuracy: 0.4759\n",
            "\n",
            "Epoch 9/20\n",
            "----------------------------------------\n",
            "Train Loss: 0.1740, Train Accuracy: 0.4835\n",
            "Validation Loss: 0.2205, Validation Accuracy: 0.4711\n",
            "\n",
            "Epoch 10/20\n",
            "----------------------------------------\n",
            "Train Loss: 0.1663, Train Accuracy: 0.4847\n",
            "Validation Loss: 0.2154, Validation Accuracy: 0.4816\n",
            "\n",
            "Epoch 11/20\n",
            "----------------------------------------\n",
            "Train Loss: 0.1602, Train Accuracy: 0.4860\n",
            "Validation Loss: 0.1959, Validation Accuracy: 0.4849\n",
            "\n",
            "Epoch 12/20\n",
            "----------------------------------------\n",
            "Train Loss: 0.1500, Train Accuracy: 0.4879\n",
            "Validation Loss: 0.1989, Validation Accuracy: 0.4790\n",
            "\n",
            "Epoch 13/20\n",
            "----------------------------------------\n",
            "Train Loss: 0.1407, Train Accuracy: 0.4892\n",
            "Validation Loss: 0.2171, Validation Accuracy: 0.4600\n",
            "\n",
            "Epoch 14/20\n",
            "----------------------------------------\n",
            "Train Loss: 0.1513, Train Accuracy: 0.4866\n",
            "Validation Loss: 0.1928, Validation Accuracy: 0.4817\n",
            "\n",
            "Epoch 15/20\n",
            "----------------------------------------\n",
            "Train Loss: 0.1296, Train Accuracy: 0.4919\n",
            "Validation Loss: 0.1845, Validation Accuracy: 0.4778\n",
            "\n",
            "Epoch 16/20\n",
            "----------------------------------------\n",
            "Train Loss: 0.1303, Train Accuracy: 0.4909\n",
            "Validation Loss: 0.1884, Validation Accuracy: 0.4795\n",
            "\n",
            "Epoch 17/20\n",
            "----------------------------------------\n",
            "Train Loss: 0.1237, Train Accuracy: 0.4925\n",
            "Validation Loss: 0.2075, Validation Accuracy: 0.4867\n",
            "\n",
            "Epoch 18/20\n",
            "----------------------------------------\n",
            "Train Loss: 0.1234, Train Accuracy: 0.4929\n",
            "Validation Loss: 0.2755, Validation Accuracy: 0.4362\n",
            "\n",
            "Epoch 19/20\n",
            "----------------------------------------\n",
            "Train Loss: 0.1324, Train Accuracy: 0.4898\n",
            "Validation Loss: 0.1728, Validation Accuracy: 0.4811\n",
            "\n",
            "Epoch 20/20\n",
            "----------------------------------------\n",
            "Train Loss: 0.1095, Train Accuracy: 0.4956\n",
            "Validation Loss: 0.1863, Validation Accuracy: 0.4890\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model(batch_seqs, batch_states)"
      ],
      "metadata": {
        "id": "m673nzAOCIVm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2170f13-21bb-4400-f4de-4073bdc25d84"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(32, 1), dtype=float32, numpy=\n",
              "array([[0.48231667],\n",
              "       [0.48240632],\n",
              "       [0.48240334],\n",
              "       [0.48240334],\n",
              "       [0.48238984],\n",
              "       [0.48054528],\n",
              "       [0.48234296],\n",
              "       [0.48237464],\n",
              "       [0.4823702 ],\n",
              "       [0.4823702 ],\n",
              "       [0.48231667],\n",
              "       [0.48222545],\n",
              "       [0.4823702 ],\n",
              "       [0.48234275],\n",
              "       [0.4823702 ],\n",
              "       [0.48231667],\n",
              "       [0.48231667],\n",
              "       [0.48240632],\n",
              "       [0.4823702 ],\n",
              "       [0.48207644],\n",
              "       [0.48234275],\n",
              "       [0.48240334],\n",
              "       [0.48236373],\n",
              "       [0.48232865],\n",
              "       [0.4822315 ],\n",
              "       [0.48215923],\n",
              "       [0.4823702 ],\n",
              "       [0.48234275],\n",
              "       [0.48240632],\n",
              "       [0.48231667],\n",
              "       [0.48240632],\n",
              "       [0.48231667]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(batch_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhdnzmlhz2Nd",
        "outputId": "1ab9d66e-ccf3-40ac-d4b4-32186f0ad88e"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[0.99735728]\n",
            " [0.99637688]\n",
            " [0.9969381 ]\n",
            " [0.99495547]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.99190468]\n",
            " [0.99623838]\n",
            " [0.99704865]\n",
            " [0.        ]\n",
            " [0.99362883]\n",
            " [0.99620954]\n",
            " [0.        ]\n",
            " [0.51013666]\n",
            " [0.98885122]\n",
            " [0.99579429]\n",
            " [0.97980182]\n",
            " [0.        ]\n",
            " [0.76107271]\n",
            " [0.99717378]\n",
            " [0.        ]\n",
            " [0.99703239]\n",
            " [0.99319677]\n",
            " [0.99507637]\n",
            " [0.99303711]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.99195264]\n",
            " [0.99514576]\n",
            " [0.98905406]\n",
            " [0.        ]\n",
            " [0.99711159]\n",
            " [0.9872774 ]\n",
            " [0.67043978]\n",
            " [0.        ]\n",
            " [0.99143798]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.99571731]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.99708682]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.99514576]\n",
            " [0.        ]\n",
            " [0.9910069 ]\n",
            " [0.99643615]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.9969701 ]\n",
            " [0.99721562]\n",
            " [0.        ]\n",
            " [0.86215229]\n",
            " [0.99661139]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.99613608]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.99725685]\n",
            " [0.99362883]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.9910069 ]\n",
            " [0.99461489]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.99652337]\n",
            " [0.99473852]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.99514576]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.63555838]\n",
            " [0.9962598 ]\n",
            " [0.99626191]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.98733365]\n",
            " [0.99611621]\n",
            " [0.9910069 ]\n",
            " [0.        ]\n",
            " [0.99732701]\n",
            " [0.9970804 ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.99514576]\n",
            " [0.99422812]\n",
            " [0.9914778 ]], shape=(100, 1), dtype=float64)\n"
          ]
        }
      ]
    }
  ]
}